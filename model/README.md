# Содержание

- [Что делает наша модель](#task1)
- [На каком алгоритме основана](#task2)
- [Как мы обрабатывали данные](#task3)
- [Какие файлы есть в репозитории и как их запустить](#task4)

# Что делает наша модель <a class="anchor" id="task1"></a>
Наша модель может подбирать код из классификатора ТНВЭД по описанию товара который должен поступать от декларанта (подающего декларацию на товар). Модель принимает описание товара и на выход подает несколько подобранных вариантов классификатора, при этом варианты ранжированы от наиболее вероятного до наименее вероятного.  

В данный момент модель может подбирать классификатор из четырех цифр, при этом классификатор состоит из десяти. Это связано с ограничениями по полученному для обучения модели датасету. Полученный датасет содержал пару "идентификатор ТНВЭД - описание" в котором идентификатор состоял из четырех цифр. Это не является ограничением модели и при наличии достаточного количества данных модель может предлагать по описанию товара классификатор из 10 цифр.

# На каком алгоритме основана <a class="anchor" id="task2"></a>
Для построения модели нами изначально было выбрано 3 алгоритма для проведения экспериментов и нахождения лучшего из них. Были протестированы такие алгоритмы как FastText, SVD, CatBoost. Мы перебрали некоторое количество параметров и обучили каждую модель не по одному разу. В итоге, нами была выбрана модель на основе алгоритма FastText, так как она показала лучшие результаты по метрике F1.  

FastText работает с векторным представлением слов и содержит предобученные векторные представления этих слов. Этот алгоритм работает несколько быстрее чем алгоритмы SVD и CatBoost. Две основные особенности которые использует алгоритм - негативное сэмплирование и subword-модель.  

Негативное сэмплирование - это подбор в цепочках слов таких сочетаний которые не являются соседями по контексту исходя из данных. Например, "шерстяной свитер" - это положительный сэмпл, а "шерстяная лопата" отрицательный.  

Subword-модель разбивает каждое слово на цепочки (n-граммы) от 3 до 6 символов, объединяет это в один список и добавляет в конце слово целиком. Это позволяет модели отсеять слова которые могут начинаться с одинаковых символов, но при этом иметь разный смысл. Также подобный подход помогают алгоритму работать со словами которые он раньше не встречал.  

# Как мы обрабатывали данные <a class="anchor" id="task3"></a>
При обучении модели очень важно качественно предобработать данные. Мы провели разведочный анализ данных, убрали повторяющиеся значения, убрали знаки препинания и лишние символы, а также избавились от описаний длиной в несколько символов. После данные были подвергнуты токенизации и лемматизации.  

Токенизация — самый первый шаг при обработке текста, результатом которого является набор (список) так называемых токенов (подстрок). Они могут быть предложениями, словами или даже отдельными символами. Иными словами, токенизация - это выделение из описания товаров основных, выделяющихся слов или фраз.  

Лемматизация – объединение слов с одним и тем же корнем или леммой, но с разными склонениями или производными значения для дальнейшего анализа как элемента. Например, лемматизировать слова «кошки», «кошек» и «кошка» означает привести к именительному падежу все эти слова и получить «кошка».  

# Какие файлы есть в репозитории и как их запустить <a class="anchor" id="task4"></a>
В данной папке репозитория находится 3 jupyter-ноутбука, по ссылкам ниже откроются ноутбуки на стороннем сервисе collab в котором их можно запустить. Предупреждаем, что выполнение может занять очень много времени, так как некоторые файлы этому сервису придется подгрузить, и расчеты занимают продолжительное время. 

**При нажатии на файл откроется сервис google, где необходимо выбрать "открыть в Colab".**
- **[clear_data.py](https://drive.google.com/file/d/1vMxMdw1QUYDBPi5CGuJmuatCuvrUjTWO/view?usp=sharing)** - ноутбук для очистки данных от повторяющихся значений, знаков препинания и лишних символов.
- **[preprocessing_data.ipynb](https://drive.google.com/file/d/1ny7R-A4mXfHOYRCHjWHAPx-BPZP-UqVd/view?usp=sharing)** - ноутбук для препроцессинга данных, токенизации и лемматизации.
- **[train_model.ipynb](https://drive.google.com/file/d/1Cv4xctl9MTV83WChOGFpj1E7OpzTh9QI/view?usp=sharing)** - основной файл, где обучается модель.
