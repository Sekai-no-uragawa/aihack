# Содержание

- [Что делает наша модель](#task1)
- [На каком алгоритме основана](#task2)
- [Как мы обрабатывали данные](#task3)
- [Какие файлы в репозитории и как их запустить](#task4)

# Что делает наша модель <a class="anchor" id="task1"></a>
Наша модель может подбирать код из классификатора ТНВЭД по описанию товара который должен поступать от декларанта (подающего декларацию на товар). Модель принимает описание товара и на выход подает несколько подобранных вариантов классификатора, при этом варианты ранжированы от наиболее вероятного до наименее вероятного.
В данный момент модель может подбирать классификатор из четырех цифр, при этом классификатор состоит из десяти. Это связано с ограничениями по полученному для обучения модели датасету. Полученный датасет содержал пару "идентификатор ТНВЭД - описание" в котором идентификатор состоял из четырех цифр. Это не является ограничением модели и при наличии достаточного количества данных модель может предлагать по описанию товара классификатор из 10 цифр.

# На каком алгоритме основана <a class="anchor" id="task2"></a>
Для построения модели нами изначально было выбрано 3 алгоритма для проведения экспериментов и нахождения лучшего из них. Были протестированы такие алгоритмы как FastText, SVD, CatBoost. Мы перебрали некоторое количество параметров и обучили каждую модель не по одному разу. В итоге, нами была выбрана модель на основе алгоритма FastText, так как она показала лучшие результаты по метрике F1.
FastText работает с векторным представлением слов и содержит предобученные векторные представления этих слов. Этот алгоритм работает несколько быстрее чем алгоритмы SVD и CatBoost. Две основные особенности которые использует алгоритм - негативное сэмплирование и subword-модель.
Негативное сэмплирование - это подбор в цепочках слов таких сочетаний которые не являются соседями по контексту исходя из данных. Например, "шерстяной свитер" - это положительный сэмпл, а "шерстяная лопата" отрицательный. 
Subword-модель разбивает каждое слово на цепочки (n-граммы) от 3 до 6 символов, объединяет это в один список и добавляет в конце слово целиком. Это позволяет модели отсеять слова которые могут начинаться с одинаковых символов, но при этом иметь разный смысл. Также подобный подход помогают алгоритму работать со словами которые он раньше не встречал.

# Как мы обрабатывали данные <a class="anchor" id="task3"></a>
При обучении модели очень важно качественно предобработать данные. Мы провели разведочный анализ данных, убрали повторяющиеся значения, убрали знаки препинания и лишние символы, а также избавились от описаний длиной в несколько символов. После данные были подвергнуты токенизации и лемматизации.


# Какие файлы в репозитории и как их запустить <a class="anchor" id="task4"></a>
