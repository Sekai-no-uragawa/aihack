import streamlit as st
import urllib.request
import fasttext
import pandas as pd
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
import pymorphy2
import re
import base64
import uuid
import json
from download_description import description_predict_from_file
from PIL import Image


st.set_page_config(
    page_title="–¢–ù –í–≠–î –ï–ê–≠–°",
    page_icon="üì¶",
    layout="wide",
)

def download_button(object_to_download, download_filename, button_text):
    """
    Generates a link to download the given object_to_download.
    From: https://discuss.streamlit.io/t/a-download-button-with-custom-css/4220
    Params:
    ------
    object_to_download:  The object to be downloaded.
    download_filename (str): filename and extension of file. e.g. mydata.csv,
    some_txt_output.txt download_link_text (str): Text to display for download
    link.
    button_text (str): Text to display on download button (e.g. 'click here to download file')
    pickle_it (bool): If True, pickle file.
    Returns:
    -------
    (str): the anchor tag to download object_to_download
    Examples:
    --------
    download_link(your_df, 'YOUR_DF.csv', 'Click to download data!')
    download_link(your_str, 'YOUR_STRING.txt', 'Click to download text!')
    """
    # if pickle_it:
    #    try:
    #        object_to_download = pickle.dumps(object_to_download)
    #    except pickle.PicklingError as e:
    #        st.write(e)
    #        return None

    # if:
    if isinstance(object_to_download, bytes):
        pass

    elif isinstance(object_to_download, pd.DataFrame):
        object_to_download = object_to_download.to_csv(index=False, encoding="CP1252")
    # Try JSON encode for everything else
    else:
        object_to_download = json.dumps(object_to_download)

    try:
        # some strings <-> bytes conversions necessary here
        b64 = base64.b64encode(object_to_download.encode()).decode()
    except AttributeError as e:
        b64 = base64.b64encode(object_to_download).decode()

    button_uuid = str(uuid.uuid4()).replace("-", "")
    button_id = re.sub("\d+", "", button_uuid)

    custom_css = f""" 
        <style>
            #{button_id} {{
                display: inline-flex;
                align-items: center;
                justify-content: center;
                background-color: rgb(255, 255, 255);
                color: rgb(38, 39, 48);
                padding: .25rem .75rem;
                position: relative;
                text-decoration: none;
                border-radius: 4px;
                border-width: 1px;
                border-style: solid;
                border-color: rgb(230, 234, 241);
                border-image: initial;
            }} 
            #{button_id}:hover {{
                border-color: rgb(246, 51, 102);
                color: rgb(246, 51, 102);
            }}
            #{button_id}:active {{
                box-shadow: none;
                background-color: rgb(246, 51, 102);
                color: white;
                }}
        </style> """

    dl_link = (
        custom_css
        + f'<a download="{download_filename}" id="{button_id}" href="data:file/txt;base64,{b64}">{button_text}</a><br><br>'
    )
    # dl_link = f'<a download="{download_filename}" id="{button_id}" href="data:file/txt;base64,{b64}"><input type="button" kind="primary" value="{button_text}"></a><br></br>'

    st.markdown(dl_link, unsafe_allow_html=True)

def _max_width_():
    max_width_str = f"max-width: 1400px;"
    st.markdown(
        f"""
    <style>
    .reportview-container .main .block-container{{
        {max_width_str}
    }}
    </style>    
    """,
        unsafe_allow_html=True,
    )
_max_width_()

@st.cache
def get_nltk():
    nltk.download('punkt')
    nltk.download('stopwords')

@st.cache
def load_model():
    url = 'https://github.com/Sekai-no-uragawa/aihack/releases/download/v1.0.1/train_all_data_default_set.fasttext_model'
    filename = url.split('/')[-1]
    urllib.request.urlretrieve(url, filename)
    return filename

@st.cache
def load_classifier():
    return pd.read_excel('data/tnved-CIS-02.xls')

@st.cache
def load_code_text():
    df_code = pd.read_csv('data/code_text.csv', dtype={'code': 'str'})
    dict_code = df_code.set_index('code').T.to_dict('list')
    return dict_code

def preprocessing(x):
    get_nltk()
    morph = pymorphy2.MorphAnalyzer()
    text = x
    if text != None:
        tock_dirt = word_tokenize(text, language="russian")
        morph_lst = []
        tock = []
        for word in tock_dirt:
            word = re.sub("[^A-Za-z–ê-–Ø–∞-—è]", " ", word)
            for i in word.split():
                if i != []:
                    if i not in stopwords.words("russian"):
                        morph_lst.append(morph.parse(i)[0].normal_form)
        return morph_lst
    else:
        return []


def main():
    
    # Sidebar -- Image/Title
    icon = Image.open("data/1024px-Emblema_fts_2020.png")
    st.sidebar.image(
        icon, use_column_width=True, caption='AiHacks 2022'
    )

    st.sidebar.markdown(
        '''
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (Fasttext)

        –î–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç:
        1. –°–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –¥–µ–∫–ª–∞—Ä–∞–Ω—Ç–æ–º
        2. –£–º–µ–Ω—å—à–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—à–∏–±–∫–∏ —á–µ–ª–æ–≤–µ–∫–∞.

        –í–æ–∑–º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –¥–≤—É—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö - –∫–∞–∫ –¥–ª—è –ø–æ–º–æ—â–∏ –¥–µ–∫–ª–∞—Ä–∞–Ω—Ç—É, —Ç–∞–∫ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ –¢–∞–º–æ–∂–µ–Ω–Ω–æ–π –°–ª—É–∂–±—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Å—Ç—É–ø–∞—é—â–∏—Ö –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–π.

        Developed by team **fit_predict**

        2022 –≥.
        '''
    )

    c10, c20, c30 = st.columns([1, 4, 1])
    with c20:
        st.title("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∞ —Ç–æ–≤–∞—Ä–∞ –¢–ù –í–≠–î –ï–ê–≠–°")
        st.write('''
        –í—ã –º–æ–∂–µ—Ç–µ –≤–≤–µ—Å—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞—à–µ–≥–æ —Ç–æ–≤–∞—Ä–∞ –≤ –ø–æ–ª–µ —Å–ª–µ–≤–∞ –∏ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π –∫–æ–¥ –∏–∑ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –í–≠–î.

        –ê —Ç–∞–∫–∂–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ .csv –≤ –æ–∫–Ω–æ —Å–ø—Ä–∞–≤–∞ –∏ –ø–æ–ª—É—á–∏—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–µ —Ç–∞–±–ª–∏—Ü—É "–û–ø–∏—Å–∞–Ω–∏–µ : –∫–æ–¥"
        ''')
    
    _, c1, c2, _= st.columns([1, 2, 2, 1])
    
    with c1:
        title = st.text_area(
                '–í–≤–µ—Å—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: ',
            )
        pred_button = st.button('–ü–æ–ª—É—á–∏—Ç—å –∫–æ–¥')

    c100, c200, c300 = st.columns([1, 4, 1])
    if pred_button:
        with c200:
            filename = load_model()
            model = fasttext.load_model(filename)
            text_preproc = ' '.join(preprocessing(title))
            ans = model.predict(text_preproc, k=5)

            st.subheader('–í–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–¥—ã, –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏')
            for_print = []
            for label, prob in zip(*ans):
                for_print.append([label[9:], round(prob,3)])
            dict_code = load_code_text()
            df = pd.DataFrame(for_print, columns=['–ö–æ–¥', '–¢–æ—á–Ω–æ—Å—Ç—å'])
            df['–û–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏'] = df['–ö–æ–¥'].map(dict_code)
            st.dataframe(df)    
    
    with c2:
        uploaded_file = st.file_uploader(
            "",
            key="1",
            help="Drop file here",
        )
    
    c100, c200, c300 = st.columns([2, 4, 2])
    if uploaded_file is not None:
        with c200:
            file_container = st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ –í—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –≤ .csv")
            shows = pd.read_csv(uploaded_file, sep=';')
            uploaded_file.seek(0)
            file_container.write(shows)
            
            filename = load_model()
            model = fasttext.load_model(filename)
            classifier = load_classifier()

            data_to_download = description_predict_from_file(shows, model, preprocessing)
            # df_xlsx = to_excel(data_to_download)
            # st.download_button(label='üì• Download Current Result',
            #                                 data=df_xlsx ,
            #                                 file_name= 'df_test.xlsx')
            CSVButton = download_button(
                data_to_download,
                "File.csv",
                "Download to CSV",
            )
    else:
        with c2:
            st.info(
                f"""
                    üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ .csv —Ñ–∞–π–ª. –§–∞–π–ª –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞: [for_test.csv](https://drive.google.com/file/d/1luxXwS7hRtCHDZLWG5pN2ybx1qrV2cxm/view?usp=sharing)
                    """
            )
            st.stop()
         
    
    
            # cat = [i[9:].replace('_', '') for i in ans]
            
            # classifier = load_classifier()
            # description = classifier[classifier.TNVED.isin(cat)].FULL_TEXT.tolist()
            # while len(description) < 5:
            #     description.append('unknown')
            
            # st.write('1.', ans[0][9:], '- –æ–ø–∏—Å–∞–Ω–∏–µ:', description[0])
            # st.write('2.', ans[1][9:], '- –æ–ø–∏—Å–∞–Ω–∏–µ:', description[1])
            # st.write('3.', ans[2][9:], '- –æ–ø–∏—Å–∞–Ω–∏–µ:', description[2])
            # st.write('4.', ans[3][9:], '- –æ–ø–∏—Å–∞–Ω–∏–µ:', description[3])
            # st.write('5.', ans[4][9:], '- –æ–ø–∏—Å–∞–Ω–∏–µ:', description[4])

if __name__ == '__main__':
    main()  